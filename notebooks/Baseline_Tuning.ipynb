{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "from pandas import CategoricalDtype\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from scipy import stats\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "backend_path = os.path.abspath('../backend')\n",
    "sys.path.append(backend_path)\n",
    "from get_metrics import get_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтение DataFrame df в файл data/df.csv\n",
    "df = pd.read_csv('../data/df.csv')\n",
    "\n",
    "# чтение DataFrame df_train в файл data/df_train.csv\n",
    "df_train = pd.read_csv('../data/df_train.csv')\n",
    "\n",
    "# чтение DataFrame df_test в файл data/df_test.csv\n",
    "df_test = pd.read_csv('../data/df_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучение модели baseline prophet\n",
    "bl_prophet = Prophet()\n",
    "bl_prophet.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# смотрим совпадение фактического курса с предсказанным курсом baseline prophet\n",
    "fig, ax = plt.subplots(figsize= (10, 5))\n",
    "\n",
    "predict = bl_prophet.predict(df_test)\n",
    "fig = bl_prophet.plot(predict, ax=ax)\n",
    "ax.scatter(df_test.ds, df_test['y'], color = 'g')\n",
    "ax.set_title('Прогноз ключевой ставки, Prophet на test')\n",
    "ax.set_ylabel('Значение ставки')\n",
    "ax.set_xlabel('Год')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# смотрим тренд, годовые и сезонные признаки\n",
    "fig = bl_prophet.plot_components(predict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выводиим метрики для оценкии baseline prophet \n",
    "metrics = get_metrics(y_test=df_test['y'], y_pred=predict['yhat'], name='Baseline Prophet')\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Mean Absolute Error (MAE) - Среднее абсолютное отклонение позволяет оценить среднее абсолютное отклонение прогнозов от фактических значений. Чем ниже MAE, тем лучше модель.\n",
    "2. Mean Absolute Percentage Error (MAPE) - Среднее абсолютное процентное отклонение показывает средний процент ошибки прогноза от фактических значений. Чем ниже MAPE, тем лучше.\n",
    "3. Mean Squared Error (MSE) - Среднеквадратичное отклонение предоставляет информацию о среднеквадратичном отклонении прогнозов от фактических значений. Чем ниже MSE, тем лучше модель.\n",
    "4. Root Mean Squared Error (RMSE) - Квадратный корень из MSE помогает интерпретировать стандартное отклонение прогнозов от фактических значений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# период, который надо отрезать и предсказать (проверка модели)\n",
    "pred_days = int(df.shape[0]*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выводиим метрики для оценкии tuning prophet \n",
    "#metrics = pd.concat([metrics, get_metrics(y_test=df_cv['y'], y_pred=df_cv['yhat'], name='CV Prophet')])\n",
    "#metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'changepoint_prior_scale': [0.01, 0.1, 1, 10],\n",
    "    'yearly_seasonality': [10, 20, 30],\n",
    "    'weekly_seasonality': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Initialize list to store cross-validation results\n",
    "results = []\n",
    "\n",
    "# Loop over parameter combinations\n",
    "for params in itertools.product(*param_grid.values()):\n",
    "    # Create a new model with the current parameter combination\n",
    "    m = Prophet(\n",
    "        changepoint_prior_scale=params[0],\n",
    "        yearly_seasonality=params[1],\n",
    "        weekly_seasonality=params[2]\n",
    "    )\n",
    "    m.fit(df_train)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_results = cross_validation(m, horizon='365 days', period='180 days', initial='730 days')\n",
    "    metrics = performance_metrics(cv_results)\n",
    "\n",
    "    # Convert params tuple to dictionary and add to metrics\n",
    "    metrics['params'] = dict(zip(['params'], [params]))\n",
    "\n",
    "    results.append(metrics)\n",
    "\n",
    "# Convert the results to a Pandas DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Find the best parameters\n",
    "best_params = df_results[df_results['mape'].idxmin()]\n",
    "\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
